{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gensim library for topic modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing data as UCI Bag of Words\n",
    "data = corpora.UciCorpus('docword.xkcd.txt', 'vocab.xkcd.txt')\n",
    "dictionary = data.create_dictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MmCorpus(1265 documents, 14352 features, 87409 non-zero entries)\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(14352 unique tokens: [b'boy', b'sits', b'barrel', b'floating', b'ocean']...)\n"
     ]
    }
   ],
   "source": [
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 49.7 s\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "%time ldamodel = models.ldamodel.LdaModel(data, id2word = dictionary, num_topics=5, passes=40, alpha=1.25, eta=1.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  save the model to save time on fitting\n",
    "ldamodel.save('ldamodel_xkcd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "ldamodel = models.ldamodel.LdaModel.load('ldamodel_xkcd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic: 0 : 0.001*\"b'paul'\" + 0.001*\"b'within'\" + 0.001*\"b'goggles'\" + 0.001*\"b'ron'\" + 0.001*\"b'relation'\" + 0.001*\"b'jelly'\" + 0.001*\"b'accurate'\" + 0.001*\"b'bean'\" + 0.001*\"b'link'\" + 0.001*\"b'han'\"\n",
      "topic: 1 : 0.002*\"b'scientist'\" + 0.001*\"b'degree'\" + 0.001*\"b'mark'\" + 0.001*\"b'leopard'\" + 0.001*\"b'nathan'\" + 0.001*\"b'summer'\" + 0.001*\"b'centigrade'\" + 0.001*\"b'shark'\" + 0.001*\"b'hurricane'\" + 0.001*\"b'marie'\"\n",
      "topic: 2 : 0.001*\"b'man'\" + 0.001*\"b'reference'\" + 0.001*\"b'turtle'\" + 0.001*\"b'boomerang'\" + 0.001*\"b'radio'\" + 0.001*\"b'destroy'\" + 0.001*\"b'yada'\" + 0.001*\"b'flu'\" + 0.001*\"b'boom'\" + 0.001*\"b'lake'\"\n",
      "topic: 3 : 0.015*\"b'man'\" + 0.012*\"b'text'\" + 0.012*\"b'person'\" + 0.010*\"b'title'\" + 0.008*\"b'guy'\" + 0.007*\"b'one'\" + 0.005*\"b'girl'\" + 0.005*\"b'just'\" + 0.005*\"b'two'\" + 0.005*\"b'hat'\"\n",
      "topic: 4 : 0.025*\"b'man'\" + 0.017*\"b'woman'\" + 0.004*\"b'boy'\" + 0.003*\"b'text'\" + 0.003*\"b'title'\" + 0.002*\"b'day'\" + 0.001*\"b'get'\" + 0.001*\"b'voice'\" + 0.001*\"b'female'\" + 0.001*\"b'girl'\"\n"
     ]
    }
   ],
   "source": [
    "# show the top words:\n",
    "for t, top_words in ldamodel.print_topics(num_topics=10, num_words=10):\n",
    "    print(f'topic: {t} : {top_words}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-8.473038992306169\n",
      "355.3357397418994\n"
     ]
    }
   ],
   "source": [
    "# calc the perplexity logarithm\n",
    "perplexity = ldamodel.log_perplexity(list(data))\n",
    "# and for whatever reason bring it to another from\n",
    "print(perplexity)\n",
    "print(2**-perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-740619.8654311746\n",
      "355.33574017213266\n"
     ]
    }
   ],
   "source": [
    "perp = ldamodel.bound(data)\n",
    "print(perp)\n",
    "print(2**(-perp/float(87409)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding new documents out from the new corpus \n",
    "# since the techer forgot to outload the 2nd corpus i'll use the same one\n",
    "data2 = corpora.UciCorpus('docword.xkcd.txt', 'vocab.xkcd.txt')\n",
    "ldamodel.update(data2, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 2.0), (1, 1.0), (2, 2.0), (3, 1.0), (4, 1.0), (5, 1.0), (6, 1.0), (7, 1.0), (8, 1.0), (9, 1.0), (10, 1.0), (11, 1.0), (12, 1.0), (13, 1.0), (14, 1.0), (15, 1.0), (16, 1.0)]\n",
      "[(0, 0.05430645), (1, 0.0633613), (2, 0.057095762), (3, 0.5326352), (4, 0.29260126)]\n"
     ]
    }
   ],
   "source": [
    "# getting the distrubution for the specific document\n",
    "doc = list(data)[0]\n",
    "print(doc)\n",
    "print(ldamodel.get_document_topics(doc))\n",
    "# i.e. for the doc[0] the most inportant is the 4th topic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
